# Facial Emotion Recognition 

This project implements a Facial Emotion Recognition system using deep learning techniques. The goal is to accurately detect and classify human emotions from facial expressions in images or real-time video feeds.

##  Overview

Facial Emotion Recognition (FER) plays a critical role in human-computer interaction, psychology, and security applications. This project leverages Convolutional Neural Networks (CNNs) to classify emotions such as:

- Angry ğŸ˜ 
- Disgust ğŸ¤¢
- Fear ğŸ˜¨
- Happy ğŸ˜„
- Sad ğŸ˜¢
- Surprise ğŸ˜²
- Neutral ğŸ˜

---

## ğŸ“ Project Structure

```bash
Facial-Emotion-recognition-/
â”œâ”€â”€ dataset/              # FER2013 dataset
â”œâ”€â”€ models/               # Saved trained model (HDF5 format)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py          # Training script
â”‚   â”œâ”€â”€ predict.py        # Prediction/inference logic
â”‚   â”œâ”€â”€ model.py          # CNN architecture definition
â”‚   â””â”€â”€ utils.py          # Helper functions
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project documentation

Model Architecture
Framework: TensorFlow / Keras

Architecture: Custom CNN

Input: 48x48 grayscale facial images

Output: 7 emotion classes

Loss Function: Categorical Cross-Entropy

Optimizer: Adam

Dataset
FER-2013: The dataset contains 35,887 grayscale images of 48x48 pixels, each labeled with one of the seven emotions.

Source: Kaggle FER2013
